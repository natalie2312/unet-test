{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "from torchvision.transforms import *\n",
    "\n",
    "\n",
    "\n",
    "save_dir = \"./data\"\n",
    "\n",
    "# u-net\n",
    "\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1, padding=1, activate=\"relu\"):\n",
    "    layers = []\n",
    "    layers.append(\n",
    "        nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=3, stride=stride, padding=padding\n",
    "        )\n",
    "    )\n",
    "    layers.append(nn.BatchNorm2d(out_channels))\n",
    "    if activate == \"relu\":\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "    elif activate == \"sigmoid\":\n",
    "        layers.append(nn.Sigmoid())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def double_conv3x3(in_channels, out_channels, stride=1, padding=1, activate=\"relu\"):\n",
    "    return nn.Sequential(\n",
    "        conv3x3(in_channels, out_channels, stride, padding=1, activate=activate),\n",
    "        conv3x3(out_channels, out_channels, stride, padding=1, activate=activate),\n",
    "    )\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownSample, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            double_conv3x3(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.bilinear = bilinear\n",
    "        self.conv_trans = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)\n",
    "        self.net = double_conv3x3(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, front, later):\n",
    "        if self.bilinear:\n",
    "            later = F.interpolate(\n",
    "                later, scale_factor=2, mode=\"bilinear\", align_corners=True\n",
    "            )\n",
    "        else:\n",
    "            later = self.conv_trans(later)\n",
    "        h_diff = front.size()[2] - later.size()[2]\n",
    "        w_diff = front.size()[3] - later.size()[3]\n",
    "        later = F.pad(\n",
    "            later,\n",
    "            pad=(w_diff // 2, w_diff - w_diff // 2, h_diff // 2, h_diff - h_diff // 2),\n",
    "            mode=\"constant\",\n",
    "            value=0,\n",
    "        )\n",
    "        x = torch.cat([front, later], dim=1)\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inconv = double_conv3x3(1, 64)\n",
    "        self.down1 = DownSample(64, 128)\n",
    "        self.down2 = DownSample(128, 256)\n",
    "        self.down3 = DownSample(256, 512)\n",
    "        self.down4 = DownSample(512, 512)\n",
    "        self.up1 = UpSample(1024, 256)\n",
    "        self.up2 = UpSample(512, 128)\n",
    "        self.up3 = UpSample(256, 64)\n",
    "        self.up4 = UpSample(128, 64)\n",
    "        self.outconv = double_conv3x3(64, 1, activate=\"sigmoid\")\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2.0 / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inconv(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x4, x5)\n",
    "        x = self.up2(x3, x)\n",
    "        x = self.up3(x2, x)\n",
    "        x = self.up4(x1, x)\n",
    "        x = self.outconv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# data loader\n",
    "\n",
    "\n",
    "class Loader(Dataset):\n",
    "    def __init__(self, split, save_dir):\n",
    "        image_dir = os.path.join(save_dir, split, \"image\")\n",
    "        label_dir = os.path.join(save_dir, split, \"label\")\n",
    "        self.images, self.labels = self._read_data(image_dir, label_dir)\n",
    "        self.trans = Compose(\n",
    "            [\n",
    "                ToPILImage(),\n",
    "                RandomHorizontalFlip(0.5),\n",
    "                RandomVerticalFlip(0.5),\n",
    "                RandomResizedCrop(572),\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _read_data(self, image_dir, label_dir):\n",
    "        images, labels = [], []\n",
    "        img_fns = os.listdir(image_dir)\n",
    "        for img_fn in img_fns:\n",
    "            image_path = os.path.join(image_dir, img_fn)\n",
    "            label_path = os.path.join(label_dir, img_fn)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "            images.append(image[np.newaxis, :])\n",
    "            label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "            label[label > 0.5] = 1\n",
    "            label[label <= 0.5] = 0\n",
    "            labels.append(label[np.newaxis, :])\n",
    "        return images, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        if np.random.uniform(0, 1) < 0.5:\n",
    "            image = image[:, ::-1, :]\n",
    "            label = label[:, ::-1, :]\n",
    "        if np.random.uniform(0, 1) < 0.5:\n",
    "            image = image[:, :, ::-1]\n",
    "            label = label[:, :, ::-1]\n",
    "\n",
    "        image = np.ascontiguousarray(image)\n",
    "        label = np.ascontiguousarray(label)\n",
    "        image = torch.from_numpy(image).float()\n",
    "        label = torch.from_numpy(label).float()\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "# functions\n",
    "\n",
    "\n",
    "def accuracy(logit, target, threshold=0.5):\n",
    "    logit[logit > threshold] = 1\n",
    "    logit[logit <= threshold] = 0\n",
    "    return (logit.long() == target.long()).float().mean().item()\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, lr_gamma=0.1):\n",
    "    for (i, param_group) in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = param_group[\"lr\"] * lr_gamma\n",
    "    return optimizer.state_dict()[\"param_groups\"][0][\"lr\"]\n",
    "\n",
    "\n",
    "# train\n",
    "\n",
    "\n",
    "def step(split, epoch, model, criterion, optimizer, batch_size=1, cuda=False):\n",
    "\n",
    "    if split == \"train\":\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    loader = data.DataLoader(\n",
    "        Loader(split, save_dir),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    epoch_loss, epoch_acc, n_batchs = 0, 0, 0\n",
    "    for i, (image, label) in enumerate(loader):\n",
    "        n_batchs += image.size(0)\n",
    "        if cuda:\n",
    "            image = image.cuda(\"cuda:1\")\n",
    "            label = label.cuda(\"cuda:1\")\n",
    "        logit = model(image)\n",
    "        logit = logit.flatten()\n",
    "        label = label.flatten()\n",
    "        loss = criterion(logit, label)\n",
    "        if split == \"train\":\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += accuracy(logit, label) * 100\n",
    "    epoch_loss /= n_batchs\n",
    "    epoch_acc /= n_batchs\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "pretrained = False\n",
    "# set Cuda = True to enable GPU calculation\n",
    "cuda = False\n",
    "start_epoch = 1\n",
    "end_epoch = 70\n",
    "lr_decay = 30\n",
    "\n",
    "print(\"init\")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = UNet()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=0.01, momentum=0.99, weight_decay=0.0005\n",
    ")\n",
    "\n",
    "print(\"optimizer\")\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda(\"cuda:1\")\n",
    "    criterion = criterion.cuda(\"cuda:1\")\n",
    "if pretrained:\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "print(\"train\")\n",
    "train_losses, val_losses = [], []\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    if epoch % lr_decay == 0:\n",
    "        lr = adjust_lr(optimizer)\n",
    "        print(\"adjust LR to {:.4f}\".format(lr))\n",
    "    tepoch_loss, tepoch_acc = step(\n",
    "        \"train\", epoch, model, criterion, optimizer, batch_size, cuda=cuda\n",
    "    )\n",
    "    vepoch_loss, vepoch_acc = step(\n",
    "        \"val\", epoch, model, criterion, optimizer, batch_size, cuda=cuda\n",
    "    )\n",
    "    train_losses.append(tepoch_loss)\n",
    "    val_losses.append(vepoch_loss)\n",
    "    print(\n",
    "        \"epoch {0:} finished, tloss:{1:.4f} [{2:.2f}%]  vloss:{3:.4f} [{4:.2f}%]\".format(\n",
    "            epoch, tepoch_loss, tepoch_acc, vepoch_loss, vepoch_acc\n",
    "        )\n",
    "    )\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"done!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}